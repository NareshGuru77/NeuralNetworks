{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork_4layers():\n",
    "    \n",
    "    def __init__(self, num_hidden_neurons = 32, learning_rate = 0.01, epochs = 3000):\n",
    "        # Layer 0 --> input, Layer 1 --> hidden, Layer 2 --> output\n",
    "        np.random.seed(0)\n",
    "        self.w_layer01 = np.random.rand(16, num_hidden_neurons)\n",
    "        self.w_layer12 = np.random.rand(num_hidden_neurons, num_hidden_neurons)\n",
    "        self.w_layer23 = np.random.rand(num_hidden_neurons, 1)\n",
    "        self.num_hidden_neurons = num_hidden_neurons\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def non_linearity(self, value, derivative = False):\n",
    "        if derivative == True:\n",
    "            return value*(1. - value)\n",
    "        value = np.array(value, dtype = np.float128)\n",
    "        value = np.clip( value, -500, 500 )\n",
    "        return 1./(1. + np.exp(-value))\n",
    "        \n",
    "    def train(self, input_array, output_array):\n",
    "        for i in range(self.epochs+1):\n",
    "            layer0 = input_array\n",
    "            layer1_local_field = input_array.dot(self.w_layer01)\n",
    "            layer1_output = self.non_linearity(layer1_local_field)\n",
    "        \n",
    "            layer2_local_field = layer1_output.dot(self.w_layer12)\n",
    "            layer2_output = self.non_linearity(layer2_local_field)\n",
    "            \n",
    "            layer3_local_field = layer2_output.dot(self.w_layer23)\n",
    "            layer3_output = self.non_linearity(layer3_local_field)\n",
    "        \n",
    "            layer3_error = layer3_output - output_array\n",
    "            layer3_delta = layer3_error * self.non_linearity(layer3_error, derivative = True)\n",
    "        \n",
    "            layer2_error = layer3_delta.dot(self.w_layer23.T)\n",
    "            layer2_delta = layer2_error * self.non_linearity(layer2_error, derivative = True)\n",
    "            \n",
    "            layer1_error = layer2_delta.dot(self.w_layer12.T)\n",
    "            layer1_delta = layer1_error * self.non_linearity(layer1_error, derivative = True)\n",
    "        \n",
    "            self.w_layer23 -= self.learning_rate * layer2_output.T.dot(layer3_delta)\n",
    "            self.w_layer12 -= self.learning_rate * layer1_output.T.dot(layer2_delta)\n",
    "            self.w_layer01 -= self.learning_rate * layer0.T.dot(layer1_delta)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print 'iteration: ', i\n",
    "                print 'error: ', np.mean(np.abs(layer3_error))\n",
    "                \n",
    "    def save_learned_weights(self):\n",
    "        np.savetxt('w_layer23.txt', self.w_layer23 , delimiter=' ')\n",
    "        np.savetxt('w_layer12.txt', self.w_layer12 , delimiter=' ')\n",
    "        np.savetxt('w_layer01.txt', self.w_layer01 , delimiter=' ')\n",
    "        \n",
    "    def load_saved_weights(self):\n",
    "        self.w_layer23 = np.loadtxt('data/16bits/weights_16bit_32hidden/w_layer23.txt')\n",
    "        self.w_layer12 = np.loadtxt('data/16bits/weights_16bit_32hidden/w_layer12.txt')\n",
    "        self.w_layer01 = np.loadtxt('data/16bits/weights_16bit_32hidden/w_layer01.txt')\n",
    "                \n",
    "    def predict(self, input_array, desired_array= None):\n",
    "        layer0 = input_array\n",
    "        layer1_local_field = input_array.dot(self.w_layer01)\n",
    "        layer1_output = self.non_linearity(layer1_local_field)\n",
    "        \n",
    "        layer2_local_field = layer1_output.dot(self.w_layer12)\n",
    "        layer2_output = self.non_linearity(layer2_local_field)\n",
    "            \n",
    "        layer3_local_field = layer2_output.dot(self.w_layer23)\n",
    "        layer3_output = self.non_linearity(layer3_local_field)\n",
    "        \n",
    "        if desired_array != None:\n",
    "            layer3_error = layer3_output - desired_array\n",
    "            print 'accuracy is ', (1.- np.mean(np.abs(layer3_error))) * 100, '%'\n",
    "        else:\n",
    "            prime_class = int(layer3_output > 0.5)\n",
    "            print 'Predicted class: ', prime_class\n",
    "            print 'Confidence in percentage: ', (\n",
    "                np.abs(1 - np.round(layer3_output, 4))*100), '%'\n",
    "\n",
    "network = NeuralNetwork_4layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 16)\n",
      "(60000, 1)\n",
      "(5535, 16)\n",
      "(5535, 1)\n"
     ]
    }
   ],
   "source": [
    "train_set_data = np.loadtxt('data/16bits/train_set_data_16bit.txt')\n",
    "train_set_labels = np.loadtxt('data/16bits/train_set_labels_16bit.txt').reshape(-1,1)\n",
    "test_set_data = np.loadtxt('data/16bits/test_set_data_16bit.txt')\n",
    "test_set_labels = np.loadtxt('data/16bits/test_set_labels_16bit.txt').reshape(-1,1)\n",
    "print train_set_data.shape\n",
    "print train_set_labels.shape\n",
    "print test_set_data.shape\n",
    "print test_set_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_batch_size = 24\n",
    "train_data_batch = np.vsplit(train_set_data, mini_batch_size)\n",
    "train_labels_batch = np.vsplit(train_set_labels, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(mini_batch_size-23):\n",
    "    print 'running mini batch number: ', i+1\n",
    "    network.train(train_data_batch[i], train_labels_batch[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  10.2439053938 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nareshguru77/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:70: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "#network.save_learned_weights()\n",
    "network.predict(test_set_data, test_set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1]]\n",
      "Predicted class:  0\n",
      "Confidence in percentage:  [ 100.0] %\n"
     ]
    }
   ],
   "source": [
    "network.load_saved_weights()\n",
    "to_predict = np.array([57]).reshape(-1,1)\n",
    "to_predict = to_predict >> np.arange(16)[::-1] & 1\n",
    "print to_predict\n",
    "network.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
